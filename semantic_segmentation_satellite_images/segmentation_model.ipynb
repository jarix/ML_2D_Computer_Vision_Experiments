{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89b28d",
   "metadata": {},
   "source": [
    "# Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a373478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGithub\\ML_2D_Computer_Vision_Experiments\\semantic_segmentation_satellite_images\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from segmentation_dataset import SegmentationDataset\n",
    "import segmentation_models_pytorch as smp \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087b31e",
   "metadata": {},
   "source": [
    "### Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e086b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9606c2",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423d18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_EPOCHS = 50\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ce226",
   "metadata": {},
   "source": [
    "### Set 'train' and 'val' Datasets & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cf0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(path_name='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = SegmentationDataset(path_name='val')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70089986",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b744f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.FPN( #  Feature Pyramid Network\n",
    "    encoder_name = \"se_resnext50_32x4d\", # Encoder - ResNeXt-50\n",
    "    encoder_weights=\"imagenet\", # Pretrained weights for encoder\n",
    "    classes=6, # Number of output classes\n",
    "    activation=\"sigmoid\" #\n",
    ") \n",
    "\n",
    "model.to(DEVICE)   # Move model to GPU if available\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # Adam optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Cross-entropy loss\n",
    "# criterion = smp.losses.DiceLoss(mode='multiclass') # Dice loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6c3ff",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f504ae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: Train Loss: 213.1577844619751, Val Loss: 10.892298579216003\n",
      "Epoch: 1: Train Loss: 192.37237656116486, Val Loss: 10.668810367584229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m running_train_loss = \u001b[32m0\u001b[39m\n\u001b[32m      9\u001b[39m running_val_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_i\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_i\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyGithub\\ML_2D_Computer_Vision_Experiments\\semantic_segmentation_satellite_images\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyGithub\\ML_2D_Computer_Vision_Experiments\\semantic_segmentation_satellite_images\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyGithub\\ML_2D_Computer_Vision_Experiments\\semantic_segmentation_satellite_images\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyGithub\\ML_2D_Computer_Vision_Experiments\\semantic_segmentation_satellite_images\\segmentation_dataset.py:50\u001b[39m, in \u001b[36mSegmentationDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# Return image & mask\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     image = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \u001b[38;5;66;03m# convert BGR to RGB\u001b[39;00m\n\u001b[32m     52\u001b[39m     image = image.transpose(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Make it BS, C, H, W\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NR_EPOCHS):\n",
    "\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    running_val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        image_i, mask_i = data\n",
    "        image = image_i.to(DEVICE)\n",
    "        mask = mask_i.to(DEVICE)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        output = model(image.float())\n",
    "\n",
    "        # Calculate losses\n",
    "        train_loss = criterion(output.float(), mask.long())\n",
    "\n",
    "        # Back propagation\n",
    "        train_loss.backward()\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_train_loss += train_loss.item()\n",
    "\n",
    "    train_losses.append(running_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    for i, data in enumerate(val_dataloader):\n",
    "        image_i, mask_i = data\n",
    "        image = image_i.to(DEVICE)\n",
    "        mask = mask_i.to(DEVICE)\n",
    "\n",
    "        # Forward Pass\n",
    "        output = model(image.float())\n",
    "\n",
    "        # Calculate losses\n",
    "        val_loss = criterion(output.float(), mask.long())\n",
    "        running_val_loss += val_loss.item()\n",
    "\n",
    "    val_losses.append(running_val_loss)\n",
    "\n",
    "    print(f\"Epoch: {epoch}: Train Loss: {np.median(running_train_loss)}, Val Loss: {np.median(running_val_loss)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e589a56",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea95c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = range(len(train_losses)), y= train_losses).set(title='Train Loss')\n",
    "plt.show()\n",
    "sns.lineplot(x = range(len(train_losses)), y= val_losses).set(title='Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50f16b",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d48c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'saved_models/FPN_epochs_{NR_EPOCHS}_crossentropy_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
